<script src="http://www.google.com/jsapi" type="text/javascript"></script> 
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif; 
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}
	
	h1 {
		font-size:32px;
		font-weight:300;
	}
	
	.disclaimerbox {
		background-color: #eee;		
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}
	
	a:link,a:visited
	{
		color: #630101;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}
	
	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}
	
	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		15px 15px 0 0px #fff, /* The fourth layer */
		15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		20px 20px 0 0px #fff, /* The fifth layer */
		20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		25px 25px 0 0px #fff, /* The fifth layer */
		25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}

	.paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35); /* The top layer shadow */

		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		5px 5px 0 0px #fff, /* The second layer */
		5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		10px 10px 0 0px #fff, /* The third layer */
		10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}
	
	.vert-cent {
		position: relative;
		top: 50%;
		transform: translateY(-50%);
	}
	
	hr
	{
		border: 0;
		height: 1px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
<head>
	<title>MambaMixer</title>
	<meta property="og:image" content="Path to my teaser.png"/> <!-- Facebook automatically scrapes this. Go to https://developers.facebook.com/tools/debug/ if you update and want to force Facebook to rescrape. -->
	<meta property="og:title" content="Creative and Descriptive Paper Title." />
	<meta property="og:description" content="Paper description." />

	<!-- Get from Google Analytics -->
	<!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src=""></script> 
	<script>
		window.dataLayer = window.dataLayer || [];
		function gtag(){dataLayer.push(arguments);}
		gtag('js', new Date());

		gtag('config', 'UA-75863369-6');
	</script>
</head>

<body>
	<br>
	<center>
		<span style="font-size:36px">MambaMixer: Efficient Selective State Space Models with Dual Token and Channel Selection</span>
		<br>
		<br>
		<table align=center width=1200px>
			<table align=center width=900px>
				<tr>
					<td align=center width=300px>
						<center>
							<span style="font-size:24px"><a href="https://abehrouz.github.io/">Ali Behrouz</a></span>
						</center>
					</td>
					<td align=center width=300px>
						<center>
							<span style="font-size:24px"><a href="https://farnooshha.github.io/">Michele Santacatterina</a></span>
						</center>
					</td>
					<td align=center width=300px>
						<center>
							<span style="font-size:24px"><a href="https://www.linkedin.com/in/sadaf-sadeghian-53b8b4174/">Ramin Zabih</a></span>
						</center>
					</td>
				</tr>
			</table>
			<br>
			<table align=center width=490px>
				<tr>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href=''>[Paper]</a></span>
						</center>
					</td>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href='https://github.com/MambaMixer/M2'>[Code]</a></span>
						</center>
					</td>
					<td align=center width=120px>
						<center>
							<span style="font-size:24px"><a href='./resources/bibtex.txt'>[Bibtex]</a></span>
						</center>
					</td>
				</tr>
			</table>
			<br>
		</table>
	</center>
	<br>
	<br>
	<center>
		<table align=center width=1200px>
			<tr>
				<td width=600px>
					<center>
						<img class="round" style="width:950px" src="./resources/teaser.png"/>
					</center>
				</td>
			</tr>
		</table>
<!-- 		<table align=center width=850px>
			<tr>
				<td>
					This was a template originally made for <a href="http://richzhang.github.io/colorization/">Colorful Image Colorization</a>. The code can be found in this <a href="https://github.com/richzhang/webpage-template">repository</a>.
				</td>
			</tr>
		</table> -->
	</center>

	<hr>

	<table align=center width=850px>
		<center><h1>Abstract</h1></center>
		<tr>
			<td>
				<p align="justify">Recent advances in deep learning have mainly relied on Transformers due to their data dependency and ability to learn at scale. The attention module in these architectures, however, exhibit quadratic time and space in input size, limiting their scalability for long-sequence modeling. Despite recent attempts to design efficient and effective architecture backbone for multi-dimensional data, such as images and multivariate time series, existing models are either data independent, or fail to allow inter- and intra-dimension communication. Recently, State Space Models (SSMs), and more specifically Selective State Space Models (S6), with efficient hardware-aware implementation, have shown promising potential for long sequence modeling. Motivated by the recent success of SSMs, we present MambaMixer block, a new architecture with data dependent weights that uses a dual selection mechanism across tokens and channelsâ€“called Selective Token and Channel Mixer. MambaMixer further connects the sequential selective mixers using a weighted averaging mechanism, allowing layers to have direct access to different layers' input and output. As a proof of concept, we design Vision MambaMixer (ViM2) and Time Series MambaMixer (TSM2) architectures based on MambaMixer block and explore their performance in various vision and time series forecasting tasks. Our results underline the importance of selectively mixing across both tokens and channels. In ImageNet classification, object detection, and semantic segmentation tasks, ViM2 achieves competitive performance with well-established vision models, i.e., ViT, MLP-Mixer, ConvMixer, and outperforms SSM-based vision models, i.e., ViM and VMamba. In time series forecasting, TSM2, an attention and MLP-free architecture, achieves outstanding performance compared to state-of-the-art methods while demonstrating significantly improved computational cost. These results show that while Transformers, cross-channel attention, and cross-channel MLPs are sufficient for good performance in practice, neither is necessary.</p> 
			</td>
		</tr>
	</table>
	<br>

	<hr>

	<center><h1>Talk</h1></center>
	<center><h3>Talk will be available soon!</h3></center>
<!-- 	<p align="center"> -->
<!-- 		<iframe width="660" height="395" src="https://www.youtube.com/embed/dQw4w9WgXcQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen align="center"></iframe> -->
<!-- 	</p> -->
	<hr>
	
	<table align=center width=850px>
		<center><h1>Motivation</h1></center>
		<tr>
			<td>
				<h3>Capturing underlying temporal and higher-order structure</h3>
				<p align="justify"> Many recent attempts to design representation learning methods for hypergraphs are equivalent to applying Graph Neural Networks (GNNs) to the clique-expansion (CE) of a hypergraph. CE is a straightforward way to generalize graph algorithms to hypergraphs by replacing hyperedges with (weighted) cliques. However, we prove that this decomposition of hyperedges limits expressiveness, leading to suboptimal performance. New methods that encode hypergraphs directly partially address this issue but these methods suffer from some combination of the following three limitations: they are designed for (1) learning the structural properties of static hypergraphs and do not consider temporal properties, (2) the transductive setting, limiting their performance on unseen patterns and data, and (3) a specific downstream task (e.g., node classification, hyperedge prediction, or subgraph classification) and cannot easily be extended to other downstream tasks, limiting their application. To address these challenges, we propose a higher-order temporal walk, called SetWalk, to capture both higher-order and temporal properties, and then design a provably powerful permutation invariant pooling method to learn the hyperedge representations. </p>
				<br>
				<h3>SetWalks</h3>
				<p align="justify"> One possible solution to capturing underlying temporal and higher-order structure is to extend the concept of a hypergraph random walk to its temporal counterpart by letting the walker walk over time. However, existing definitions of random walks on hypergraphs offer limited expressivity and sometimes degenerate to simple walks on the CE of the hypergraph. There are two reasons for this: (1) Random walks are composed of a sequence of pair-wise interconnected vertices, even though edges in a hypergraph connect sets of vertices. Decomposing them into sequences of simple pair-wise interactions loses the semantic meaning of the hyperedges. (2) A sampling probability of a walk on a hypergraph must be different from its sampling probability on the CE of the hypergraph. To this end, we present a new temporal higher-order walks, called SetWalk, where each random walk is a sequence of hyperedges (i.e., in each step of walk sampling, we sample an adjacent hyperedge). </p>
				<br>
				<h3>SetMixer</h3>
				<p align="justify">  </p>
			</td>
		</tr>
	</table>
	<br>
	
	<hr>

	<table align=center width=850px>
		<center><h1>Method</h1></center>
		<tr>
			<center>
				<table align=center width=1200px>
					<tr>
						<td width=600px>
							<center>
								<img class="round" style="width:800px" src="./resources/method_diagram.png"/>
							</center>
						</td>
					</tr>
				</table>
			</center>
		</tr>
	</table>
	<br>

	<hr>

	<table align=center width=850px>
		<center><h1>Experiments</h1></center>
		<tr>
			<td>
				<h3>Hyperedge Prediction:</h3>
				<p align="justify">  </p>
					<center>
						<table align=center width=1200px>
							<tr>
								<td width=600px>
									<center>
										<img class="round" style="width:900px" src="./resources/he_result.png"/>
									</center>
								</td>
							</tr>
						</table>
					</center>
				<br>
					
				<h3>Node Classification:</h3>
				<p align="justify">  </p>
					<center>
						<table align=center width=1200px>
							<tr>
								<td width=600px>
									<center>
										<img class="round" style="width:550px" src="./resources/node_result.png"/>
									</center>
								</td>
							</tr>
						</table>
					</center>
				<br>
					
				<h3>MLP-Mixer vs RNNs:</h3>
				<p align="justify">  </p>
				<center>
					<table align=center width=1200px>
						<tr>
							<td width=600px>
								<center>
									<img class="round" style="width:800px" src="./resources/rnn_result.png"/>
								</center>
							</td>
						</tr>
					</table>
				</center>
			</td>
		</tr>
	</table>
	<br>
	
	<hr>
	

	<table align=center width=800px>
		<br>
		<tr><center>
			<span style="font-size:28px">&nbsp;<a href='https://github.com/ubc-systopia/CATWalk'>Code, Data, and Trained Models</a>
			</center>
		</span>
	</table>
	<table align=center width=400px>
		<tr>
			<td align=center width=400px>
				<center>
					<a href="https://github.com/ubc-systopia/CATWalk">
				        <img class="round" style="width:300px" src="./resources/Github.png"/>
				    	</a>
				</center>
			</td>
		</tr>
	</table>
	<br>
	<hr>
	<table align=center width=1000px>
		<center><h1>Paper and Supplementary Material</h1></center>
		<tr>
			<td><a href=""><img class="layered-paper-big" style="height:175px" src="./resources/paper.png"/></a></td>
			<td><span style="font-size:14pt">A. Behrouz, F. Hashemi, S. Sadeghian, M. Seltzer.<br>
				<b>CAT-Walk: Inductive Hypergraph Learning via Set Walks.</b><br>
				In Thirty-seventh Conference on Neural Information Processing Systems, NeurIPS 2023.<br>
				(<a href="https://openreview.net/forum?id=QG4nJBNEar">Openreview</a>)<br>
				<!-- (<a href="./resources/camera-ready.pdf">camera ready</a>)<br> -->
<!-- 				<span style="font-size:4pt"><a href=""><br></a> -->
<!-- 				</span> -->
			</td>
		</tr>
	</table>
	<br>

	<hr>
	<br>

	<table align=center width=900px>
		<tr>
			<td width=400px>
				<left>
					<center><h1>Acknowledgements</h1></center>
					This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a> for a <a href="http://richzhang.github.io/colorization/">colorful</a> ECCV project; the code can be found <a href="https://github.com/richzhang/webpage-template">here</a>.
				</left>
			</td>
		</tr>
	</table>

<br>
</body>
</html>

